{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfd5776",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1aa15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch torchvision matplotlib pandas scikit-learn tqdm seaborn\n",
    "\n",
    "import os\n",
    "import random\n",
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "# ========================== 1. CONFIG ==========================\n",
    "SEED = 42\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n",
    "\n",
    "BASE_DATA_DIR = \"/content/drive/MyDrive/Vﾄ食ﾄ神TTNT/Skin cancer ISIC The International Skin Imaging Collaboration\"\n",
    "TRAIN_DIR = os.path.join(BASE_DATA_DIR, \"Train\")\n",
    "TEST_DIR = os.path.join(BASE_DATA_DIR, \"Test\")\n",
    "\n",
    "NUM_CLASSES = 9\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 50\n",
    "LEARNING_RATE = 1e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "T_MAX = 20\n",
    "OVERSAMPLE_FACTOR = 5\n",
    "NUM_WORKERS = 4\n",
    "PIN_MEMORY = True if device == 'cuda' else False\n",
    "PATIENCE = 6\n",
    "USE_FOCAL = True\n",
    "\n",
    "BASE_PATH = \"/content/drive/MyDrive/Vﾄ食ﾄ神TTNT/VGG16_Results\"\n",
    "LOG_DIR = os.path.join(BASE_PATH, \"logs\")\n",
    "CKPT_DIR = os.path.join(BASE_PATH, \"checkpoints\")\n",
    "BEST_DIR = os.path.join(BASE_PATH, \"best_model\")\n",
    "RESULT_DIR = os.path.join(BASE_PATH, \"results\")\n",
    "\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "os.makedirs(CKPT_DIR, exist_ok=True)\n",
    "os.makedirs(BEST_DIR, exist_ok=True)\n",
    "os.makedirs(RESULT_DIR, exist_ok=True)\n",
    "\n",
    "LOG_CSV = os.path.join(LOG_DIR, \"training_log.csv\")\n",
    "\n",
    "# Seed\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# ========================== 2. LABEL MAP ==========================\n",
    "label_map = {\n",
    "    0: 'actinic keratosis',\n",
    "    1: 'basal cell carcinoma',\n",
    "    2: 'dermatofibroma',\n",
    "    3: 'melanoma',\n",
    "    4: 'nevus',\n",
    "    5: 'pigmented benign keratosis',\n",
    "    6: 'seborrheic keratosis',\n",
    "    7: 'squamous cell carcinoma',\n",
    "    8: 'vascular lesion'\n",
    "}\n",
    "\n",
    "# ========================== 3. RAW DATASET ==========================\n",
    "train_dataset_raw = datasets.ImageFolder(TRAIN_DIR)\n",
    "test_dataset = datasets.ImageFolder(TEST_DIR)\n",
    "\n",
    "# ========================== 4. TRANSFORMS / AUGMENT ==========================\n",
    "class RandomAugmentationPerImage:\n",
    "    def __init__(self):\n",
    "        self.augmentations = [\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomVerticalFlip(p=0.5),\n",
    "            transforms.RandomRotation(40),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2)\n",
    "        ]\n",
    "        self.resize = transforms.Resize((224,224))\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        self.normalize = transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img = self.resize(img)\n",
    "        for aug in self.augmentations:\n",
    "            if torch.rand(1) < 0.5:\n",
    "                img = aug(img)\n",
    "        img = self.to_tensor(img)\n",
    "        img = self.normalize(img)\n",
    "        return img\n",
    "\n",
    "transform_train = RandomAugmentationPerImage()\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6970b7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================== 5. PLOT SAMPLE & CLASS DISTRIBUTION ==========================\n",
    "def plot_class_distribution(labels, label_map, title=\"Class Distribution\"):\n",
    "    counter = Counter(labels)\n",
    "    total = sum(counter.values())\n",
    "    print(f\"--- {title} ---\")\n",
    "    for i in range(len(label_map)):\n",
    "        count = counter[i]\n",
    "        print(f\"{i} ({label_map[i]}): {count} samples | {count/total*100:.2f}%\")\n",
    "    counts = [counter[i] for i in range(len(label_map))]\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.pie(counts, labels=[label_map[i] for i in range(len(label_map))],\n",
    "            autopct='%1.1f%%', startangle=140)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Original distribution\n",
    "original_labels = [label for _, label in train_dataset_raw.imgs]\n",
    "plot_class_distribution(original_labels, label_map, title=\"Original Train Distribution\")\n",
    "\n",
    "# Show 5 random images before augmentation\n",
    "fig, axes = plt.subplots(1,5, figsize=(15,4))\n",
    "for i, ax in enumerate(axes):\n",
    "    img, label = train_dataset_raw[random.randint(0,len(train_dataset_raw)-1)]\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(label_map[label])\n",
    "    ax.axis('off')\n",
    "plt.suptitle(\"Sample Original Images\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaa825d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================== 6. OVERSAMPLING ==========================\n",
    "targets = [train_dataset_raw.imgs[i][1] for i in range(len(train_dataset_raw.imgs))]\n",
    "class_counts = Counter(targets)\n",
    "max_count = max(class_counts.values()) * OVERSAMPLE_FACTOR\n",
    "weights_per_class = {cls: max_count/count for cls, count in class_counts.items()}\n",
    "sample_weights = np.array([weights_per_class[t] for t in targets])\n",
    "indices = np.random.choice(len(targets), size=len(targets)*OVERSAMPLE_FACTOR, replace=True, p=sample_weights/sample_weights.sum())\n",
    "\n",
    "class OversampledDataset(Dataset):\n",
    "    def __init__(self, base_dataset, indices, transform=None):\n",
    "        self.base_dataset = base_dataset\n",
    "        self.indices = indices\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.base_dataset[self.indices[idx]]\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "train_dataset_full = OversampledDataset(train_dataset_raw, indices, transform=transform_train)\n",
    "\n",
    "# Show 5 augmented images\n",
    "fig, axes = plt.subplots(1,5, figsize=(15,4))\n",
    "for i, ax in enumerate(axes):\n",
    "    img, label = train_dataset_full[random.randint(0,len(train_dataset_full)-1)]\n",
    "    img_np = img.permute(1,2,0).numpy()\n",
    "    img_np = (img_np - img_np.min()) / (img_np.max() - img_np.min())  # denormalize for display\n",
    "    ax.imshow(img_np)\n",
    "    ax.set_title(label_map[label])\n",
    "    ax.axis('off')\n",
    "plt.suptitle(\"Sample Augmented Images\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad263a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================== 7. SPLIT TRAIN / VAL ==========================\n",
    "oversampled_imgs = [train_dataset_raw.imgs[i] for i in indices]\n",
    "paths, labels = zip(*oversampled_imgs)\n",
    "paths = np.array(paths)\n",
    "labels = np.array(labels)\n",
    "\n",
    "train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "    paths, labels, test_size=0.3, stratify=labels, random_state=SEED\n",
    ")\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, paths, labels, transform=None):\n",
    "        self.paths = np.array(paths)\n",
    "        self.labels = np.array(labels)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.paths[idx]).convert('RGB')\n",
    "        label = int(self.labels[idx])\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "train_loader = DataLoader(CustomDataset(train_paths, train_labels, transform=transform_train),\n",
    "                          batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "\n",
    "val_loader = DataLoader(CustomDataset(val_paths, val_labels, transform=transform_val),\n",
    "                        batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "\n",
    "test_paths = [p for p,_ in test_dataset.imgs]\n",
    "test_labels = [l for _, l in test_dataset.imgs]\n",
    "test_loader = DataLoader(CustomDataset(test_paths, test_labels, transform=transform_val),\n",
    "                         batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "\n",
    "# Distribution after oversampling\n",
    "plot_class_distribution(train_labels, label_map, title=\"Train Distribution After Oversampling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73b4b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================== 8. CLASS WEIGHTS & LOSS ==========================\n",
    "train_labels_for_weights = train_labels.astype(int)\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(train_labels_for_weights), y=train_labels_for_weights)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2, weight=None, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce = nn.CrossEntropyLoss(weight=self.weight, reduction='none')(inputs, targets)\n",
    "        pt = torch.exp(-ce)\n",
    "        loss = ((1 - pt) ** self.gamma * ce)\n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        else:\n",
    "            return loss\n",
    "\n",
    "criterion = FocalLoss(gamma=2.0, weight=class_weights) if USE_FOCAL else nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# ========================== 9. EARLY STOPPING ==========================\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, delta=0.0):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_f1 = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, f1):\n",
    "        if self.best_f1 is None:\n",
    "            self.best_f1 = f1\n",
    "            return\n",
    "        if f1 < self.best_f1 + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_f1 = f1\n",
    "            self.counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b299b995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================== 10. VGG16 MODEL ==========================\n",
    "class VGG16Model(nn.Module):\n",
    "    def __init__(self, num_classes=NUM_CLASSES, pretrained=True):\n",
    "        super().__init__()\n",
    "        # Load pretrained VGG16\n",
    "        self.vgg16 = models.vgg16(pretrained=pretrained)\n",
    "        \n",
    "        # Freeze early layers\n",
    "        for param in self.vgg16.features[:20].parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Replace classifier\n",
    "        num_features = self.vgg16.classifier[6].in_features\n",
    "        self.vgg16.classifier[6] = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.vgg16(x)\n",
    "\n",
    "model = VGG16Model(num_classes=NUM_CLASSES).to(device)\n",
    "print(f\"Model loaded on {device}\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters())}\")\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24518d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================== 11. TRAIN / EVAL FUNCTIONS ==========================\n",
    "def train_one_epoch(model, loader, optimizer, criterion, device, epoch):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    loop = tqdm(enumerate(loader), total=len(loader), desc=f\"Epoch {epoch} [TRAIN]\")\n",
    "    for i, (imgs, labels) in loop:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        preds = outputs.argmax(1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        loop.set_postfix(loss=running_loss/(i+1), acc=correct/total)\n",
    "    return running_loss/len(loader), correct/total\n",
    "\n",
    "def eval_one_epoch(model, loader, criterion, device, epoch):\n",
    "    model.eval()\n",
    "    running_loss, correct, total = 0.0,0,0\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        loop = tqdm(enumerate(loader), total=len(loader), desc=f\"Epoch {epoch} [VAL]\")\n",
    "        for i, (imgs, labels) in loop:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            preds = outputs.argmax(1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            loop.set_postfix(loss=running_loss/(i+1), acc=correct/total)\n",
    "    macro_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    return running_loss/len(loader), correct/total, macro_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40ad82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================== 12. TRAINING LOOP ==========================\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=T_MAX)\n",
    "early_stopper = EarlyStopping(patience=PATIENCE)\n",
    "\n",
    "best_f1 = 0.0\n",
    "best_epoch = 0\n",
    "history = {\"train_loss\": [], \"val_loss\": [], \"train_acc\": [], \"val_acc\": [], \"f1\": []}\n",
    "\n",
    "with open(LOG_CSV, 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"epoch\",\"train_loss\",\"train_acc\",\"val_loss\",\"val_acc\",\"macro_f1\"])\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device, epoch)\n",
    "    val_loss, val_acc, val_macro_f1 = eval_one_epoch(model, val_loader, criterion, device, epoch)\n",
    "\n",
    "    scheduler.step()\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['f1'].append(val_macro_f1)\n",
    "\n",
    "    with open(LOG_CSV, 'a', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([epoch, train_loss, train_acc, val_loss, val_acc, val_macro_f1])\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        ckpt_path = os.path.join(CKPT_DIR, f'model_epoch_{epoch}.pt')\n",
    "        torch.save(model.state_dict(), ckpt_path)\n",
    "        print(' Saved checkpoint:', ckpt_path)\n",
    "\n",
    "    if val_macro_f1 > best_f1:\n",
    "        best_f1 = val_macro_f1\n",
    "        best_epoch = epoch\n",
    "        best_path = os.path.join(BEST_DIR, 'best_model_vgg16.pt')\n",
    "        torch.save(model.state_dict(), best_path)\n",
    "        print(f' Best model updated at epoch {epoch} | F1={best_f1:.4f}')\n",
    "\n",
    "    print(f'Epoch {epoch}/{NUM_EPOCHS} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} | Macro F1: {val_macro_f1:.4f}')\n",
    "\n",
    "    early_stopper(val_macro_f1)\n",
    "    if early_stopper.early_stop:\n",
    "        print('>>> Early stopping triggered. Stopping training.')\n",
    "        break\n",
    "\n",
    "print('\\nTraining completed. Best Epoch =', best_epoch, '| Best F1 =', best_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d43ef04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================== 13. PLOT METRICS ==========================\n",
    "plt.figure(figsize=(16,5))\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(history['train_loss'], label='Train Loss')\n",
    "plt.plot(history['val_loss'], label='Val Loss')\n",
    "plt.title('Loss Curve')\n",
    "plt.legend()\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(history['train_acc'], label='Train Acc')\n",
    "plt.plot(history['val_acc'], label='Val Acc')\n",
    "plt.title('Accuracy Curve')\n",
    "plt.legend()\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(history['f1'], label='Macro F1')\n",
    "plt.title('Macro F1 Curve')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(RESULT_DIR, 'training_curves_vgg16.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fad0076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================== 14. CONFUSION MATRIX & TEST ==========================\n",
    "best_model_path = os.path.join(BEST_DIR, 'best_model_vgg16.pt')\n",
    "if os.path.exists(best_model_path):\n",
    "    model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "    print('Loaded best model from', best_model_path)\n",
    "\n",
    "def plot_confusion(loader, title, save_path):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            preds = outputs.argmax(1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', xticklabels=label_map.values(), yticklabels=label_map.values(), cmap=\"Blues\")\n",
    "    plt.title(title)\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.xlabel(\"Pred\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=45)\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion(val_loader, \"Validation Confusion Matrix (VGG16)\", os.path.join(RESULT_DIR,\"val_conf_matrix_vgg16.png\"))\n",
    "plot_confusion(test_loader, \"Test Confusion Matrix (VGG16)\", os.path.join(RESULT_DIR,\"test_conf_matrix_vgg16.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e43bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================== 15. DETAILED EVALUATION ==========================\n",
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        outputs = model(imgs)\n",
    "        preds = outputs.argmax(1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "all_labels = np.array(all_labels)\n",
    "all_preds = np.array(all_preds)\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(all_labels, all_preds, target_names=list(label_map.values()))\n",
    "print(\"\\nClassification Report (VGG16):\\n\", report)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=label_map.values(), yticklabels=label_map.values(), cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix (Validation - VGG16)\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.xlabel(\"Pred\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Sample count per class\n",
    "counter = Counter(all_labels)\n",
    "print(\"\\nNumber of samples per class in validation set:\")\n",
    "for i, name in label_map.items():\n",
    "    print(f\"{name}: {counter[i]}\")\n",
    "\n",
    "# ROC & AUC per class\n",
    "y_test_bin = label_binarize(all_labels, classes=list(range(NUM_CLASSES)))\n",
    "y_score_bin = label_binarize(all_preds, classes=list(range(NUM_CLASSES)))\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "for i in range(NUM_CLASSES):\n",
    "    fpr, tpr, _ = roc_curve(y_test_bin[:,i], y_score_bin[:,i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, lw=2, label=f'{label_map[i]} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "plt.plot([0,1],[0,1],'k--', lw=2)\n",
    "plt.xlim([0.0,1.0])\n",
    "plt.ylim([0.0,1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve per Class (Validation - VGG16)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
